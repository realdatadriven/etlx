+++
title = 'Dynamic Queries'
weight = 61
draft = false
+++

# Dynamic Query Generation (`get_dyn_queries[...]`)

In some advanced ETL workflows, you may need to dynamically generate SQL queries based on metadata or schema differences between the source and destination databases.

---

## **üîπ Why Use Dynamic Queries?**

‚úÖ **Schema Flexibility** ‚Äì Automatically adapt to schema changes in the source system.  
‚úÖ **Self-Evolving Workflows** ‚Äì ETL jobs can generate and execute additional SQL queries as needed.  
‚úÖ **Automation** ‚Äì Reduces the need for manual intervention when new columns appear.  

## **üîπ How `get_dyn_queries[query_name](runs_before,runs_after)` Works**

- Dynamic queries are executed using the **`get_dyn_queries[query_name](runs_before,runs_after)`** pattern.
- During execution, **ETLX runs the query** `query_name` and **retrieves dynamically generated queries**.
- The **resulting queries are then executed automatically**.

## **üõ† Example: Auto-Adding Missing Columns**

This example **checks for new columns in a JSON file** and **adds them to the destination table**.

### **üìÑ Markdown Configuration for `get_dyn_queries[query_name](runs_before,runs_after)`**

>If the `query_name` depends on attaching and detaching the main db where it will run, those should be passed as dependencies, because the dynamic queries are generate before any other query and put in the list for the list where it is to be executed, to be a simpler flow, but they are optional otherwise.

````markdown
....

```yaml metadata
...
connection: "duckdb:"
before_sql:
  - ...
  - get_dyn_queries[create_missing_columns]  # Generates queries defined in `create_missing_columns` and  Executes them
..
```

**üìú SQL Query (Generating Missing Columns)**

```sql
-- create_missing_columns
WITH source_columns AS (
    SELECT column_name, column_type 
    FROM (DESCRIBE SELECT * FROM read_json('<fname>'))
),
destination_columns AS (
    SELECT column_name, data_type as column_type
    FROM duckdb_columns 
    WHERE table_name = '<table>'
),
missing_columns AS (
    SELECT s.column_name, s.column_type
    FROM source_columns s
    LEFT JOIN destination_columns d ON s.column_name = d.column_name
    WHERE d.column_name IS NULL
)
SELECT 'ALTER TABLE "<table>" ADD COLUMN "' || column_name || '" ' || column_type || ';' AS query
FROM missing_columns
WHERE (SELECT COUNT(*) FROM destination_columns) > 0;
```
````

---

## **üõ† Execution Flow**

1Ô∏è‚É£ **Extract column metadata from the input (in this case a json file, but it could be a table or any other valid query).**  
2Ô∏è‚É£ **Check which columns are missing in the destination table (`<table>`).**  
3Ô∏è‚É£ **Generate `ALTER TABLE` statements for adding missing columns, and replaces the `- get_dyn_queries[create_missing_columns]` with the the generated queries**  
4Ô∏è‚É£ **Runs the workflow with dynamically generated queries against the destination connection.**

## **üîπ Key Features**

‚úî **Fully automated schema updates**  
‚úî **Works with flexible schema data (e.g., JSON, CSV, Parquet, etc.)**  
‚úî **Reduces manual maintenance when source schemas evolve**  
‚úî **Ensures destination tables always match source structure**

---

**With `get_dyn_queries[...]`, your ETLX workflows can now dynamically evolve with changing data structures!**