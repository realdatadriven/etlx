{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`httpfs`](https://duckdb.org/docs/extensions/httpfs/s3api, \"httpfs\") extension supports reading/writing/globbing files on object storage servers using the S3 API. S3 offers a standard API to read and write to remote files (while regular http servers, predating S3, do not offer a common write API). DuckDB conforms to the S3 API, that is now common among industry storage providers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preferred way to configure and authenticate to S3 endpoints is to use secrets. Multiple secret providers are available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml metadata\n",
    "name: S3_EXTRACT\n",
    "description: \"Example extrating from S3 to a local sqlite3 file\"\n",
    "connection: \"duckdb:\"\n",
    "active: true\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml metadata\n",
    "name: train_services\n",
    "description: \"train_services\"\n",
    "table: train_services\n",
    "load_conn: \"duckdb:\"\n",
    "load_before_sql:\n",
    "  - load_extentions\n",
    "  - attach_db\n",
    "load_sql: load_query\n",
    "load_after_sql: detach_db\n",
    "drop_sql: drop_sql\n",
    "clean_sql: clean_sql\n",
    "rows_sql: nrows\n",
    "active: true\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- load_extentions\n",
    "INSTALL Sqlite;\n",
    "LOAD Sqlite;\n",
    "INSTALL httpfs;\n",
    "LOAD httpfs;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- attach_db\n",
    "ATTACH 'examples/S3_EXTRACT.db' AS \"DB\" (TYPE SQLITE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- detach_db\n",
    "DETACH \"DB\";\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- load_query\n",
    "CREATE OR REPLACE TABLE \"DB\".\"<table>\" AS\n",
    "FROM 's3://duckdb-blobs/train_services.parquet';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- drop_sql\n",
    "DROP TABLE IF EXISTS \"DB\".\"<table>\";\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- clean_sql\n",
    "DELETE FROM \"DB\".\"<table>\";\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- nrows\n",
    "SELECT COUNT(*) AS \"nrows\" FROM \"DB\".\"<table>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3_EXTRACT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml metadata\n",
    "name: S3_EXTRACT\n",
    "description: \"Example extrating from S3 to a local sqlite3 file\"\n",
    "table: S3_EXTRACT\n",
    "load_conn: \"duckdb:\"\n",
    "load_before_sql:\n",
    "  - load_extentions\n",
    "  - attach_db\n",
    "  - create_S3_token\n",
    "load_sql: load_query\n",
    "load_after_sql: detach_db\n",
    "drop_sql: drop_sql\n",
    "clean_sql: clean_sql\n",
    "rows_sql: nrows\n",
    "active: true\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- load_extentions\n",
    "INSTALL httpfs;\n",
    "LOAD httpfs;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- attach_db\n",
    "ATTACH 'examples/S3_EXTRACT.db' AS \"DB\" (TYPE SQLITE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example with a [Minio](https://min.io/) local instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- create_S3_token\n",
    "CREATE SECRET S3_token (\n",
    "   TYPE S3,\n",
    "   KEY_ID '@S3_KEY_ID',\n",
    "   SECRET '@S3_SECRET',\n",
    "   ENDPOINT '127.0.0.1:3000',\n",
    "   URL_STYLE 'path'\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- detach_db\n",
    "DETACH \"DB\";\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- load_query\n",
    "CREATE OR REPLACE TABLE \"DB\".\"<table>\" AS\n",
    "SELECT * \n",
    "FROM 's3://uploads/flights.csv';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- drop_sql\n",
    "DROP TABLE IF EXISTS \"DB\".\"<table>\";\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- clean_sql\n",
    "DELETE FROM \"DB\".\"<table>\";\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- nrows\n",
    "SELECT COUNT(*) AS \"nrows\" FROM \"DB\".\"<table>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "bin/etlx --config examples/s3.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "bin/etlx --config examples/s3.ipynb\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
