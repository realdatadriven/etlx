<!doctype html><html lang=en-US dir=ltr><head><meta name=generator content="Hugo 0.153.5"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content><link rel=icon href=/favicon.ico sizes=any><link rel=apple-touch-icon href=/favicon.ico><link rel=preload href=/icons/clipboard.svg as=image type=image/svg+xml><link rel=preload href=/icons/caret-down.svg as=image type=image/svg+xml><link rel=preload href=/icons/caret-right.svg as=image type=image/svg+xml><link rel=preload href=/icons/home.svg as=image type=image/svg+xml><title>ETLX</title><meta name=description content="ETLX is an open-source, developer-first ETL framework designed to make data pipelines **simpler, faster, and more maintainable**. It focuses on **clarity, portability, and performance**, allowing you to build reliable data workflows without heavy orchestration platforms or vendor lock-in."><meta name=keywords content="ETL,ELT,Data Integration,DuckDB,Markdown,SQL,Data Processing,Framework,Data Engineering,Data Pipelines,Data Transformation,Data Science,Data Analytics,Open Source,Data Governance,Data Documentation,Data Workflows,Data Workflow Documentation,Report Automation"><meta name=author content="Real Data-Driven"><meta name=language content="en-US"><link rel=canonical href=https://realdatadriven.github.io/etlx/><link rel=manifest href=https://realdatadriven.github.io/etlx/manifest.webmanifest><meta property="og:title" content="ETLX"><meta property="og:description" content="ETLX is an open-source, developer-first ETL framework designed to make data pipelines **simpler, faster, and more maintainable**. It focuses on **clarity, portability, and performance**, allowing you to build reliable data workflows without heavy orchestration platforms or vendor lock-in."><meta property="og:type" content="website"><meta property="og:url" content="https://realdatadriven.github.io/etlx/"><meta property="og:locale" content="en-US"><meta property="og:site_name" content="ETLX"><meta property="og:image" content="https://realdatadriven.github.io/favicon.ico"><meta property="og:image:width" content="512"><meta property="og:image:height" content="512"><meta property="og:image:alt" content="ETLX logo"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="ETLX"><meta name=twitter:description content="ETLX is an open-source, developer-first ETL framework designed to make data pipelines **simpler, faster, and more maintainable**. It focuses on **clarity, portability, and performance**, allowing you to build reliable data workflows without heavy orchestration platforms or vendor lock-in."><meta name=twitter:image content="https://realdatadriven.github.io/favicon.ico"><meta name=twitter:image:alt content="ETLX logo"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https:\/\/realdatadriven.github.io\/etlx\/#website","url":"https:\/\/realdatadriven.github.io\/etlx\/","name":"ETLX","description":"ETL \/ ELT Framework powered by DuckDB, designed to seamlessly integrate and process data from diverse sources. It leverages Markdown as a configuration medium, where YAML blocks define metadata for each data source, and embedded SQL blocks specify the extraction, transformation, and loading logic.","publisher":{"@id":"https:\/\/realdatadriven.github.io\/etlx\/#organization"}}]}</script><link rel=stylesheet href=/etlx/css/style.min.c8b8d34bfceb040e8957f73bca811dcf496446066a07c4298993517af10bc79e.css integrity="sha256-yLjTS/zrBA6JV/c7yoEdz0lkRgZqB8QpiZNRevELx54=" crossorigin=anonymous></head><body class="has-toc has-sidebar"><a class=skip-link href=#main-content>Skip to main content</a><header class=header><button class=header__sidebar--toggle data-action=toggle-sidebar title="Toggle sidebar"></button><a class=header__title href=/>ETLX</a><nav class=menu><ul><li><a aria-current=page class=active href=/etlx/>Home</a></li><li><a href=/etlx/introduction/>Introduction</a></li><li><a href=/etlx/quick-start/>Quick Start</a></li><li><a href=/etlx/configuration/>Configuration</a></li><li><a href=/etlx/advanced/>Advanced</a></li><li><a href=/etlx/embedding/>Embedding</a></li><li><a href=/etlx/future/>Future</a></li><li><a href=/etlx/license/>License</a></li></ul></nav><button class=header__menu--toggle data-action=toggle-menu title="Toggle menu"></button></header><aside class=sidebar><div class=sidebar__content><button class=sidebar__close data-action=toggle-sidebar title="Close sidebar"></button><div class=sidebar__section--search><input name=q placeholder=Search... type=search><ul class=sidebar__section--search-results></ul></div><nav class=sidebar__nav><ul class=sidebar__section--pages><li><a class=sidebar__section--header href=/etlx/>Home</a></li><li><a class=sidebar__section--header href=/etlx/introduction/>Introduction</a></li><li><a class=sidebar__section--header href=/etlx/quick-start/>Quick Start</a></li><li><a class=sidebar__section--header href=/etlx/configuration/>Configuration</a></li><li><a class=sidebar__section--header href=/etlx/advanced/>Advanced</a></li><li><a class=sidebar__section--header href=/etlx/embedding/>Embedding</a></li><li><a class=sidebar__section--header href=/etlx/future/>Future</a></li><li><a class=sidebar__section--header href=/etlx/license/>License</a></li></ul></nav></div><footer class=footer><div class=footer__social-links><a href=https://github.com/realdatadriven/etlx target=_blank rel="noopener noreferrer"><div title=GitHub><div aria-hidden=true><svg width="24" height="24" viewBox="0 0 24 24"><path fill="currentColor" d="M5.315 2.1c.791-.113 1.9.145 3.333.966l.272.161.16.1.397-.083a13.3 13.3.0 014.59-.08l.456.08.396.083.161-.1c1.385-.84 2.487-1.17 3.322-1.148l.164.008.147.017.076.014.05.011.144.047a1 1 0 01.53.514 5.2 5.2.0 01.397 2.91l-.047.267-.046.196.123.163c.574.795.93 1.728 1.03 2.707l.023.295L21 9.5c0 3.855-1.659 5.883-4.644 6.68l-.245.061-.132.029.014.161.008.157.004.365-.002.213L16 21a1 1 0 01-.883.993L15 22H9a1 1 0 01-.993-.883L8 21v-.734c-1.818.26-3.03-.424-4.11-1.878l-.535-.766c-.28-.396-.455-.579-.589-.644l-.048-.019a1 1 0 01.564-1.918c.642.188 1.074.568 1.57 1.239l.538.769c.76 1.079 1.36 1.459 2.609 1.191L8 17.562l-.018-.168a5 5 0 01-.021-.824l.017-.185.019-.12-.108-.024c-2.976-.71-4.703-2.573-4.875-6.139l-.01-.31L3 9.5a5.6 5.6.0 01.908-3.051l.152-.222.122-.163-.045-.196a5.2 5.2.0 01.145-2.642l.1-.282.106-.253a1 1 0 01.529-.514l.144-.047z"/></svg></div></div></a></div></footer></aside><div class=sidebar__backdrop data-action=toggle-sidebar></div><main id=main-content><h1>ETLX</h1><hr><h1 id=etlx>ETLX</h1><p><strong>A modern, composable ETL framework built for data engineers</strong></p><p>ETLX is an open-source, developer-first ETL framework designed to make data pipelines <strong>simpler, faster, and more maintainable</strong>.
It focuses on <strong>clarity, portability, and performance</strong>, allowing you to build reliable data workflows without heavy orchestration platforms or vendor lock-in.</p><hr><h2 id=-why-etlx>ğŸš€ Why ETLX?</h2><p>Modern data stacks are powerful â€” but often overcomplicated.</p><p>ETLX takes a different approach:</p><ul><li><strong>Code-first, configuration-driven</strong></li><li><strong>Database-centric</strong>, powered by DuckDB</li><li><strong>Composable pipelines</strong>, not monolithic workflows</li><li><strong>Local-first</strong>, but production-ready</li></ul><p>Whether you&rsquo;re building a one-off data pipeline or a repeatable data product, ETLX gives you full control with minimal overhead.</p><hr><h2 id=-core-concepts>ğŸ§± Core Concepts</h2><h3 id=-declarative-pipelines>ğŸ”¹ Declarative Pipelines</h3><p>Define what should happen, not how.
ETLX handles execution order, dependencies, and validation.</p><h3 id=-duckdb-at-the-core>ğŸ”¹ DuckDB at the Core</h3><p>Leverage DuckDB for:</p><ul><li>In-process analytics</li><li>SQL-first transformations</li><li>Efficient joins across files, APIs, and databases</li></ul><h3 id=-multiple-data-sources>ğŸ”¹ Multiple Data Sources</h3><p>Work seamlessly with:</p><ul><li>Files (CSV, Parquet, JSON, Excel, &mldr;)</li><li>Databases (Postgres, SQLite, DuckDB, ODBC, &mldr; any DBMS with a DuckDB Extention)</li><li>APIs & external systems</li></ul><h3 id=-reproducible--portable>ğŸ”¹ Reproducible & Portable</h3><p>ETLX pipelines are:</p><ul><li>Version-controlled</li><li>Environment-agnostic</li><li>Easy to run locally, in CI, or in containers</li></ul><hr><h2 id=-example-workflow>ğŸ§© Example Workflow</h2><figure class=code-block role=figure aria-label="md code snippet"><button class=highlight__copy title="Copy to clipboard"></button><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-md data-lang=md><span class=line><span class=cl><span class=gh># INPUTS
</span></span></span><span class=line><span class=cl><span class=s>```yaml
</span></span></span><span class=line><span class=cl><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>INPUTS</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>description</span><span class=p>:</span><span class=w> </span><span class=l>Extracts data from source and load on target</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>runs_as</span><span class=p>:</span><span class=w> </span><span class=l>ETL</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>active</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=s>```</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=gu>## INPUT_1
</span></span></span><span class=line><span class=cl><span class=s>```yaml
</span></span></span><span class=line><span class=cl><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>INPUT_1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>description</span><span class=p>:</span><span class=w> </span><span class=l>Input 1 from an ODBC Source</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>table</span><span class=p>:</span><span class=w> </span><span class=l>INPUT_1</span><span class=w> </span><span class=c># Destination Table</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>load_conn</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;duckdb:&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>load_before_sql</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=s2>&#34;ATTACH &#39;ducklake:@DL_DSN_URL&#39; AS DL (DATA_PATH &#39;s3://dl-bucket...&#39;)&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=s2>&#34;ATTACH &#39;@OLTP_DSN_URL&#39; AS PG (TYPE POSTGRES)&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>load_sql</span><span class=p>:</span><span class=w> </span><span class=l>load_input_in_dl</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>load_on_err_match_patt</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;(?i)table.+with.+name.+(\w+).+does.+not.+exist&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>load_on_err_match_sql</span><span class=p>:</span><span class=w> </span><span class=l>create_input_in_dl</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>load_after_sql</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>DETACH DL</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>DETACH pg</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>active</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=s>```</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s>```sql
</span></span></span><span class=line><span class=cl><span class=c1>-- load_input_in_dl
</span></span></span><span class=line><span class=cl><span class=k>INSERT</span><span class=w> </span><span class=k>INTO</span><span class=w> </span><span class=n>DL</span><span class=p>.</span><span class=n>INPUT_1</span><span class=w> </span><span class=k>BY</span><span class=w> </span><span class=n>NAME</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=k>SELECT</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=n>PG</span><span class=p>.</span><span class=n>INPUT_1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=s>```</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s>```sql
</span></span></span><span class=line><span class=cl><span class=c1>-- create_input_in_dl
</span></span></span><span class=line><span class=cl><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>DL</span><span class=p>.</span><span class=n>INPUT_1</span><span class=w> </span><span class=k>AS</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=k>SELECT</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=n>PG</span><span class=p>.</span><span class=n>INPUT_1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=s>```</span>
</span></span><span class=line><span class=cl>...</span></span></code></pre></td></tr></table></div></div></figure><blockquote><p><code>@DL_DSN_URL</code> (e.g. <code>mysql:db=ducklake_catalog host=your_mysql_host</code>) and
<code>@OLTP_DSN_URL</code> (e.g. <code>postgres:dbname=erpdb host=your_postgres_host user=postgres password=your_pass</code>) are <strong>environment variables</strong> used to define database connection strings.</p></blockquote><blockquote><p>They can be provided through a <code>.env</code> file located at the root of the project and are automatically loaded at runtime.</p></blockquote><blockquote><p>These variables allow ETLX to connect to different data sources without hardcoding credentials, making configurations portable, secure, and environment-agnostic.</p></blockquote><p>Run it with:</p><figure class=code-block role=figure aria-label="bash code snippet"><button class=highlight__copy title="Copy to clipboard"></button><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>etlx run --config pipeline.md</span></span></code></pre></td></tr></table></div></div></figure><p>Simple. Transparent. Repeatable.</p><hr><h2 id=-built-for-engineers>ğŸ› ï¸ Built for Engineers</h2><p>ETLX is designed for teams who want:</p><ul><li>ğŸ§  Full control over transformations</li><li>ğŸ” Debuggable, inspectable execution</li><li>âš¡ Fast local iteration</li><li>ğŸ“¦ Clean separation between logic and infrastructure</li></ul><p>No black boxes. No hidden state.</p><hr><h2 id=-use-cases>ğŸŒ Use Cases</h2><ul><li>Data ingestion & normalization</li><li>Analytics pipelines</li><li>Data quality validation</li><li>Lightweight ELT for analytics teams</li><li>Prototyping before production pipelines</li></ul><hr><h2 id=-multi-engine-by-design>ğŸ”Œ Multi-Engine by Design</h2><p>While <strong>DuckDB is the default and recommended execution engine</strong>, ETLX is designed to be <strong>engine-agnostic</strong>.</p><p>Depending on your use case, pipelines can run on:</p><ul><li><strong>DuckDB</strong> (recommended for analytics, local-first, and embedded workloads)</li><li><strong>PostgreSQL</strong></li><li><strong>SQLite</strong></li><li><strong>MySQL / MariaDB</strong></li><li><strong>SQL Server</strong></li><li>Any engine supported through <strong>ODBC or DuckDB extensions</strong></li></ul><p>This allows ETLX to adapt to:</p><ul><li>Local development and experimentation</li><li>On-prem or cloud-hosted databases</li><li>Hybrid architectures mixing analytical and operational systems</li></ul><p>DuckDB remains the <strong>best fit for analytical workloads</strong>, but ETLX does not lock you into a single execution engine.</p><hr><h2 id=-metadata-driven-by-design>ğŸ§  Metadata-Driven by Design</h2><p>ETLX pipelines are more than just execution instructions â€”
they are <strong>structured metadata documents</strong>.</p><p>Every pipeline definition can describe:</p><ul><li>Inputs and outputs</li><li>Field-level transformations</li><li>Business meaning and context</li><li>Data ownership and responsibility</li><li>Validation rules and expectations</li></ul><p>This means your pipeline definition can also serve as:</p><ul><li>ğŸ“˜ <strong>Living documentation</strong></li><li>ğŸ§­ <strong>Data lineage source</strong></li><li>ğŸ“Š <strong>Data dictionary</strong></li><li>ğŸ›¡ï¸ <strong>Governance metadata</strong></li></ul><p>All from the same configuration.</p><hr><h2 id=-self-documenting-pipelines>ğŸ§¾ Self-Documenting Pipelines</h2><p>Because ETLX pipelines are defined as structured text, they can be <strong>parsed, analyzed, and rendered</strong> into documentation automatically.</p><p>From a single pipeline definition, you can generate:</p><ul><li>Table-level and column-level lineage</li><li>Field descriptions and transformation logic</li><li>Source â†’ target mappings</li><li>Ownership and domain information</li><li>SQL logic and derived field explanations</li></ul><p>This makes ETLX suitable for:</p><ul><li>Technical documentation portals</li><li>Data catalogs</li><li>Governance and compliance reporting</li><li>Automated lineage visualization</li></ul><hr><h2 id=-metadata--documentation--governance>ğŸ“Š Metadata â†’ Documentation â†’ Governance</h2><p>ETLX treats metadata as a <strong>first-class citizen</strong>.</p><p>When properly defined, the same configuration can power:</p><table><thead><tr><th>Capability</th><th>Generated From</th></tr></thead><tbody><tr><td>Data dictionary</td><td>Field metadata</td></tr><tr><td>Lineage graphs</td><td>Source & transformation mapping</td></tr><tr><td>Transformation logic docs</td><td>SQL + metadata</td></tr><tr><td>Ownership & domain mapping</td><td>Dataset attributes</td></tr><tr><td>Audit & governance views</td><td>Execution metadata</td></tr></tbody></table><p>In other words:</p><blockquote><p><strong>Your pipeline configuration becomes your documentation.</strong></p></blockquote><p>No duplicated effort. No drift.</p><hr><h2 id=-designed-for-automation--ai-assistance>ğŸ§© Designed for Automation & AI Assistance</h2><p>Because ETLX configurations are structured, readable, and machine-friendly:</p><ul><li>They can be validated automatically</li><li>Used to generate documentation sites</li><li>Fed into LLMs for explanation, validation, or review</li><li>Used to auto-generate data contracts or schema docs</li></ul><p>This makes ETLX an ideal foundation for <strong>metadata-driven data platforms</strong>.</p><h2 id=-full-observability--execution-traceability>ğŸ§¾ Full Observability & Execution Traceability</h2><p>Every ETLX execution is <strong>fully observable by design</strong>.</p><p>Each pipeline, step, and sub-step automatically captures detailed runtime metadata, making executions transparent, auditable, and debuggable â€” without requiring external tooling.</p><p>For every run, ETLX records:</p><ul><li>â± <strong>Start time and end time</strong></li><li>âŒ› <strong>Execution duration</strong></li><li>ğŸ’¾ <strong>Memory usage and resource footprint</strong></li><li>âœ… <strong>Validation results</strong></li><li>âš ï¸ <strong>Warnings and failed conditions</strong></li><li>ğŸ” <strong>Retries and conditional branches</strong></li><li>ğŸ“ <strong>Execution status per step and sub-step</strong></li></ul><p>This information is available at <strong>pipeline</strong>, <strong>task</strong>, and <strong>sub-task</strong> levels.</p><hr><h2 id=-fine-grained-execution-details>ğŸ” Fine-Grained Execution Details</h2><p>Each process and sub-process exposes:</p><ul><li>Input and output metadata</li><li>Validation rules applied and their results</li><li>Conditional logic evaluation (why a step ran or was skipped)</li><li>Error context and failure reason (when applicable)</li></ul><p>This allows you to fully reconstruct <strong>what happened, when, and why</strong> â€” even long after execution.</p><hr><h2 id=-built-in-operational-metadata>ğŸ“Š Built-In Operational Metadata</h2><p>All execution metadata can be:</p><ul><li>Stored alongside pipeline results</li><li>Queried using SQL</li><li>Exported for observability platforms</li><li>Used to generate execution reports</li></ul><p>This enables:</p><ul><li>Performance analysis over time</li><li>SLA and reliability tracking</li><li>Root-cause analysis</li><li>Auditable operational history</li></ul><hr><h2 id=-configuration-as-the-source-of-truth>ğŸ§© Configuration as the Source of Truth</h2><p>ETLX treats configuration as <strong>executable documentation</strong>.</p><p>The same configuration that defines:</p><ul><li>Sources and targets</li><li>Transformations</li><li>Validation rules</li><li>Conditions and dependencies</li></ul><p>â€¦also defines:</p><ul><li>What is logged</li><li>How it is validated</li><li>What metadata is captured</li><li>How execution should be interpreted</li></ul><p>This makes every pipeline <strong>self-describing</strong>, reproducible, and reviewable.</p><hr><h2 id=-designed-for-observability-governance--scale>ğŸ§  Designed for Observability, Governance & Scale</h2><p>By combining:</p><ul><li>Structured configuration</li><li>Deterministic execution</li><li>Rich metadata capture</li></ul><p>ETLX enables:</p><ul><li>End-to-end lineage generation</li><li>Data quality reporting</li><li>Governance and compliance workflows</li><li>Auditable execution trails</li></ul><p>All without introducing external orchestration complexity.</p><hr><hr><h2 id=-beyond-etl-reporting-document--template-generation>ğŸ“„ Beyond ETL: Reporting, Document & Template Generation</h2><p>ETLX is not limited to traditional extractâ€“transformâ€“load workflows.</p><p>Because it operates on structured data and metadata, ETLX can also be used as a <strong>general-purpose data-driven document generator</strong>.</p><p>This makes it suitable for producing:</p><ul><li>ğŸ“Š Analytical reports</li><li>ğŸ“‘ Regulatory and compliance documents</li><li>ğŸ“ˆ Periodic exports and structured files</li><li>ğŸ§¾ Human-readable and machine-readable outputs</li></ul><p>All from the same pipeline definitions.</p><hr><h2 id=-structured-outputs-from-structured-data>ğŸ§© Structured Outputs from Structured Data</h2><p>ETLX can generate and populate:</p><ul><li><strong>Spreadsheets</strong> (Excel, CSV)</li><li><strong>Formatted reports</strong> (HTML, Markdown, PDF)</li><li><strong>Machine-readable formats</strong> (JSON, XML, YAML)</li><li><strong>Templated documents</strong> (e.g. regulatory submissions, internal reports)</li></ul><p>Templates can be defined once and reused across executions, while the data, metadata, and transformations remain fully traceable.</p><hr><h2 id=-reporting--regulatory-use-cases>ğŸ“Š Reporting & Regulatory Use Cases</h2><p>ETLX is well suited for:</p><ul><li>Regulatory submissions</li><li>Financial and operational reporting</li><li>Periodic disclosures</li><li>Standardized data exchanges</li><li>Audit and compliance documentation</li></ul><p>By combining structured metadata with deterministic execution, ETLX ensures that generated outputs are:</p><ul><li>Consistent</li><li>Reproducible</li><li>Auditable</li><li>Aligned with defined business rules</li></ul><hr><h2 id=-metadata-driven-templates>ğŸ§  Metadata-Driven Templates</h2><p>Templates can reference:</p><ul><li>Dataset fields and transformations</li><li>Derived metrics and calculations</li><li>Validation results and rule outcomes</li><li>Execution metadata (timestamps, versions, sources)</li></ul><p>This allows the same pipeline to produce both:</p><ul><li>The <strong>data</strong></li><li>And the <strong>documentation explaining that data</strong></li></ul><p>All from a single source of truth.</p><hr><h2 id=-one-pipeline-many-outputs>ğŸ§¾ One Pipeline, Many Outputs</h2><p>A single ETLX pipeline can simultaneously:</p><ul><li>Load and transform data</li><li>Generate analytical tables</li><li>Produce formatted reports</li><li>Export structured files</li><li>Emit metadata for governance systems</li></ul><p>This reduces duplication, manual work, and inconsistencies across reporting layers.</p><hr><h2 id=-summary>ğŸ”š Summary</h2><p>ETLX is not just an ETL tool.</p><p>It is a <strong>declarative, metadata-first execution framework</strong> that:</p><ul><li>Runs across multiple SQL engines and data platforms</li><li>Produces fully <strong>auditable, inspectable, and reproducible</strong> pipelines</li><li>Captures execution metadata, validations, timings, and lineage at every step</li><li>Bridges engineering, analytics, and governance in a single workflow</li><li>Turns configuration into <strong>executable documentation</strong></li><li>Enables generation of <strong>reports, datasets, and structured outputs</strong> (tables, files, templates)</li><li>Supports <strong>data lineage, data dictionaries, and governance artifacts</strong> by design</li></ul><p>From data ingestion to reporting and documentation, ETLX provides a unified, transparent, and extensible foundation for building trustworthy data systems.</p><hr><h2 id=-open-source--extensible>ğŸ“¦ Open Source & Extensible</h2><p>ETLX is open source and designed to grow with your needs.</p><p>You can:</p><ul><li>Extend it with custom operators</li><li>Integrate it into CI/CD</li><li>Embed it inside larger data platforms</li></ul><p>ğŸ‘‰ Source code:
<a href=https://github.com/realdatadriven/etlx rel=external>https://github.com/realdatadriven/etlx</a></p><hr><h2 id=-getting-started>ğŸš€ Getting Started</h2><figure class=code-block role=figure aria-label="bash code snippet"><button class=highlight__copy title="Copy to clipboard"></button><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>git clone https://github.com/realdatadriven/etlx
</span></span><span class=line><span class=cl><span class=nb>cd</span> etlx</span></span></code></pre></td></tr></table></div></div></figure><p>Documentation, examples, and guides are available throughout this site.</p></main><aside id=toc class=toc><div class=toc__header data-action=toggle-toc><h3 class=toc__title>On this page</h3><button class=toc__toggle aria-label="Toggle table of contents"></button></div><div class=toc__content><nav id=TableOfContents><ul><li><a href=#-why-etlx>ğŸš€ Why ETLX?</a></li><li><a href=#-core-concepts>ğŸ§± Core Concepts</a><ul><li><a href=#-declarative-pipelines>ğŸ”¹ Declarative Pipelines</a></li><li><a href=#-duckdb-at-the-core>ğŸ”¹ DuckDB at the Core</a></li><li><a href=#-multiple-data-sources>ğŸ”¹ Multiple Data Sources</a></li><li><a href=#-reproducible--portable>ğŸ”¹ Reproducible & Portable</a></li></ul></li><li><a href=#-example-workflow>ğŸ§© Example Workflow</a></li><li><a href=#-built-for-engineers>ğŸ› ï¸ Built for Engineers</a></li><li><a href=#-use-cases>ğŸŒ Use Cases</a></li><li><a href=#-multi-engine-by-design>ğŸ”Œ Multi-Engine by Design</a></li><li><a href=#-metadata-driven-by-design>ğŸ§  Metadata-Driven by Design</a></li><li><a href=#-self-documenting-pipelines>ğŸ§¾ Self-Documenting Pipelines</a></li><li><a href=#-metadata--documentation--governance>ğŸ“Š Metadata â†’ Documentation â†’ Governance</a></li><li><a href=#-designed-for-automation--ai-assistance>ğŸ§© Designed for Automation & AI Assistance</a></li><li><a href=#-full-observability--execution-traceability>ğŸ§¾ Full Observability & Execution Traceability</a></li><li><a href=#-fine-grained-execution-details>ğŸ” Fine-Grained Execution Details</a></li><li><a href=#-built-in-operational-metadata>ğŸ“Š Built-In Operational Metadata</a></li><li><a href=#-configuration-as-the-source-of-truth>ğŸ§© Configuration as the Source of Truth</a></li><li><a href=#-designed-for-observability-governance--scale>ğŸ§  Designed for Observability, Governance & Scale</a></li><li><a href=#-beyond-etl-reporting-document--template-generation>ğŸ“„ Beyond ETL: Reporting, Document & Template Generation</a></li><li><a href=#-structured-outputs-from-structured-data>ğŸ§© Structured Outputs from Structured Data</a></li><li><a href=#-reporting--regulatory-use-cases>ğŸ“Š Reporting & Regulatory Use Cases</a></li><li><a href=#-metadata-driven-templates>ğŸ§  Metadata-Driven Templates</a></li><li><a href=#-one-pipeline-many-outputs>ğŸ§¾ One Pipeline, Many Outputs</a></li><li><a href=#-summary>ğŸ”š Summary</a></li><li><a href=#-open-source--extensible>ğŸ“¦ Open Source & Extensible</a></li><li><a href=#-getting-started>ğŸš€ Getting Started</a></li></ul></nav></div></aside><script defer crossorigin=anonymous integrity="sha256-KXMijDfasiR2erJ0tgywvcZ1CHvBNdFv6ZTL8PGWBIE=" src=/etlx/js/bundle.2973228c37dab224767ab274b60cb0bdc675087bc135d16fe994cbf0f1960481.js></script></body></html>